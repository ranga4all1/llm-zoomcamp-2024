{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6a2a42-06a5-4243-86e6-88afae343b94",
   "metadata": {},
   "source": [
    "## Load documents with IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2671454-293e-47fb-a764-ded026cea2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:50:13.114243Z",
     "iopub.status.busy": "2024-07-31T19:50:13.113862Z",
     "iopub.status.idle": "2024-07-31T19:50:13.683576Z",
     "shell.execute_reply": "2024-07-31T19:50:13.682937Z",
     "shell.execute_reply.started": "2024-07-31T19:50:13.114214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4861e8e-4bb0-4fb6-ae6d-0cf5b5bb13a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:50:21.953109Z",
     "iopub.status.busy": "2024-07-31T19:50:21.952732Z",
     "iopub.status.idle": "2024-07-31T19:50:21.960399Z",
     "shell.execute_reply": "2024-07-31T19:50:21.959560Z",
     "shell.execute_reply.started": "2024-07-31T19:50:21.953085Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'ea739c65'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00820287-bfc5-40c4-8616-b5c3ab94a7f1",
   "metadata": {},
   "source": [
    "## Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b866849-73ab-4bcd-9622-26732d919028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:50:58.815522Z",
     "iopub.status.busy": "2024-07-31T19:50:58.815135Z",
     "iopub.status.idle": "2024-07-31T19:51:00.748996Z",
     "shell.execute_reply": "2024-07-31T19:51:00.748157Z",
     "shell.execute_reply.started": "2024-07-31T19:50:58.815498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65ac3a9-a4a1-4eca-a3ba-5f47fac1d909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:51:08.188728Z",
     "iopub.status.busy": "2024-07-31T19:51:08.188329Z",
     "iopub.status.idle": "2024-07-31T19:51:08.194067Z",
     "shell.execute_reply": "2024-07-31T19:51:08.193235Z",
     "shell.execute_reply.started": "2024-07-31T19:51:08.188702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b816a7-de45-4d03-87c1-d83acf1fd8fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:51:44.351122Z",
     "iopub.status.busy": "2024-07-31T19:51:44.350706Z",
     "iopub.status.idle": "2024-07-31T19:51:44.356291Z",
     "shell.execute_reply": "2024-07-31T19:51:44.355695Z",
     "shell.execute_reply.started": "2024-07-31T19:51:44.351096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx = {d['id']: d for d in documents}\n",
    "doc_idx['5170565b']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3e895-e646-4fd9-8456-46df2b839f29",
   "metadata": {},
   "source": [
    "## Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a7c242-aced-43e9-b541-9d784f966e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T19:52:10.207780Z",
     "iopub.status.busy": "2024-07-31T19:52:10.207394Z",
     "iopub.status.idle": "2024-07-31T19:52:19.683064Z",
     "shell.execute_reply": "2024-07-31T19:52:19.682358Z",
     "shell.execute_reply.started": "2024-07-31T19:52:10.207755Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477b946084cc4762a5eb1f1277a0a0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c783e240684541bc6ac18c74ba2ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578b74fb152c41d6bc3ebc8afdcf41e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fbdaf5ad7b4cb1a027f8610dbd0aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d883986b89734ae3b1ef70e0f9b356e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f960cef5c04bc09b2f1eb5b54376c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed6a97542f14d7b8a421a407268a6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973b65b5dfdf4e6da39aea65d0bb16e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38e4ac57d494359a1a2007a6897faf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1875f634f5ef4c4c8395d877f77d6317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3bacfd2d894d4395377b24c227d986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec66cccec094f7aab9eae143f195f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272a76866c874dee966f4ddfde61109b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a2dbd6630c4dbbb0cc713d0d9ebe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda055c99ab541488c710efc296e9e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585f341-2f2e-4961-b653-ef98f2c2e466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be329f5-bba3-4998-b4c3-50c45e33dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    doc['question_text_vector'] = model.encode(question + ' ' + text)\n",
    "\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d09a0-0991-4c49-9c04-edc3bae3a162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T20:07:15.793497Z",
     "iopub.status.busy": "2024-07-31T20:07:15.793078Z",
     "iopub.status.idle": "2024-07-31T20:07:15.797283Z",
     "shell.execute_reply": "2024-07-31T20:07:15.796558Z",
     "shell.execute_reply.started": "2024-07-31T20:07:15.793468Z"
    },
    "tags": []
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e28200b-7d63-4cdc-8fa9-3db7e453fd49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T20:07:31.809629Z",
     "iopub.status.busy": "2024-07-31T20:07:31.809225Z",
     "iopub.status.idle": "2024-07-31T20:07:31.815699Z",
     "shell.execute_reply": "2024-07-31T20:07:31.814959Z",
     "shell.execute_reply.started": "2024-07-31T20:07:31.809605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5b1be-c805-43de-bbdf-9422eaf12918",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text_vector_knn(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd666958-1ade-4d01-adfd-3113ea8cad29",
   "metadata": {},
   "source": [
    "## The RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a3e2c-b4c7-4f7e-b6a9-9ffd259aa833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = promp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41b974-2f5d-4c65-a8df-a8e3f7ff67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b57fb5-b8d1-4050-90ad-246dfbe33b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict, model='gpt-4o') -> str:\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca81a2-b72c-4660-acb7-f035af82219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac5ff1-2657-41f6-90b4-3e294b95c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab4a92-6880-4d91-8650-d90f796c36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx['5170565b']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103a09e-9541-4769-9839-2da7bb716e25",
   "metadata": {},
   "source": [
    "## Cosine similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54e624-7823-4ac6-981e-a283a4a27d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_orig = 'Yes, sessions are recorded if you miss one. Everything is recorded, allowing you to catch up on any missed content. Additionally, you can ask questions in advance for office hours and have them addressed during the live stream. You can also ask questions in Slack.'\n",
    "answer_llm = 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'\n",
    "\n",
    "v_llm = model.encode(answer_llm)\n",
    "v_orig = model.encode(answer_orig)\n",
    "\n",
    "v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e84de-f33a-4c83-8172-7df6dc76c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec964f-4af9-4519-b096-5d5de2086eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d0ae6-2753-45c2-aebe-19f85b26173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359d4c9-4687-433b-b0ce-d87ef179a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e716113-6b2d-47da-8171-01533c858c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rec in enumerate(tqdm(ground_truth)):\n",
    "    if i in answers:\n",
    "        continue\n",
    "\n",
    "    answer_llm = rag(rec)\n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec7ee0-5312-4538-b2c7-dbb7555ab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4o = [None] * len(ground_truth)\n",
    "\n",
    "for i, val in answers.items():\n",
    "    results_gpt4o[i] = val.copy()\n",
    "    results_gpt4o[i].update(ground_truth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52765374-cfe3-4500-96fb-2096c60c5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0c4c8-1183-4f76-934f-a31e3f3728ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o = pd.DataFrame(results_gpt4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5bf83-4709-429c-a3f1-1cb98c529c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fb420-5d89-4eae-981a-d34299002a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o.to_csv('data/results-gpt4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f983c-9009-4680-b61f-7102a4693bc4",
   "metadata": {},
   "source": [
    "## Evaluating GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48063b41-14b3-4e66-b11c-9a85b8971366",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(ground_truth[10], model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2837c8c-ffc3-4786-b416-cdc835b801d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988060c-5ecb-473d-98fd-e5e55fa7df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(rec):\n",
    "    model = 'gpt-3.5-turbo'\n",
    "    answer_llm = rag(rec, model=model)\n",
    "    \n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b60dc-daa8-41a4-b0af-b58ee974c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_record(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4813af-4871-47d7-83fe-2431ccf41b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt35 = map_progress(pool, ground_truth, process_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6de4f-b066-459c-bfb7-655d0c2372cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt35 = pd.DataFrame(results_gpt35)\n",
    "df_gpt35.to_csv('data/results-gpt35.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d1921-a2cc-4d67-b261-ff871953db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/results-gpt35.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed23b64-c802-42cf-b7aa-d88a84bf9843",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "\n",
    "A->Q->A' cosine similarity\n",
    "\n",
    "A -> Q -> A'\n",
    "\n",
    "cosine(A, A')\n",
    "\n",
    "## gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b251c3-c9ab-4aad-a726-36a08d2dae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4o = df_gpt4o.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b06055-2546-4739-9ed8-871d29e1af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = results_gpt4o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bb5d1-3067-408a-99e1-d7446803b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_orig = model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29317f05-ea96-4d61-840f-7d23c438f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "\n",
    "for record in tqdm(results_gpt4o):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab6da7-8f1d-428e-b0a2-25621b25ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o['cosine'] = similarity\n",
    "df_gpt4o['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a975b8c-bca6-4b28-a75a-be79a1509704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb15da-743f-4d0f-b933-926edef1b032",
   "metadata": {},
   "source": [
    "## gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486ca33-c373-4702-913b-6269650d3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt35 = df_gpt35.to_dict(orient='records')\n",
    "\n",
    "similarity_35 = []\n",
    "\n",
    "for record in tqdm(results_gpt35):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity_35.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed822b0-234b-44c2-98a2-5454019dcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt35['cosine'] = similarity_35\n",
    "df_gpt35['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34abfbf-9e94-4d6b-9c6f-d86e8cd20e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457442cb-a4c3-4003-8aa0-56cfc29f283a",
   "metadata": {},
   "source": [
    "## gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fbaab7e-6909-4346-b282-19c6375461d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T20:13:56.886988Z",
     "iopub.status.busy": "2024-07-31T20:13:56.886603Z",
     "iopub.status.idle": "2024-07-31T20:13:56.891745Z",
     "shell.execute_reply": "2024-07-31T20:13:56.890877Z",
     "shell.execute_reply.started": "2024-07-31T20:13:56.886964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_record_4o_mini(rec):\n",
    "    model = 'gpt-4o-mini'\n",
    "    answer_llm = rag(rec, model=model)\n",
    "    \n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_orig = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e4682-8a99-48c3-9444-27ecaddaf245",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_record_4o_mini(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c328c9c-0173-4a0a-b666-9dabe24664ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4omini = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309897d-8d1a-4d3c-a209-dc6d15faf6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tqdm(ground_truth):\n",
    "    result = process_record_4o_mini(record)\n",
    "    results_gpt4omini.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dba8f-7a2c-49d2-aca9-3d7456eec473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o_mini = pd.DataFrame(results_gpt4omini)\n",
    "df_gpt4o_mini.to_csv('data/results-gpt4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bf8cb-7efa-40f0-baed-4bdf30bac6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_4o_mini = []\n",
    "\n",
    "for record in tqdm(results_gpt4omini):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity_4o_mini.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f11b1d-0458-42df-b765-e250c9138370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o_mini['cosine'] = similarity_4o_mini\n",
    "df_gpt4o_mini['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96e5e4-901a-4ef4-b047-4b8d4e3fe32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_gpt35['cosine'], label='3.5')\n",
    "\n",
    "sns.distplot(df_gpt4o['cosine'], label='4o')\n",
    "sns.distplot(df_gpt4o_mini['cosine'], label='4o-mini')\n",
    "\n",
    "plt.title(\"RAG LLM performance\")\n",
    "plt.xlabel(\"A->Q->A' Cosine Similarity\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bbf0bc-85b7-43fa-bcc7-36a65422018c",
   "metadata": {},
   "source": [
    "## LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f219714-b529-495a-bd90-0c6079868345",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc87e9-e754-472d-be88-b53b71bde2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_gpt4o_mini.sample(n=150, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f18ec-f5c8-4978-9593-22c0c2ae57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14f846-79f8-4853-bf01-215ee394c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = samples[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76074db1-6217-4cfc-ad5a-ba04447e008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e18bd5-516b-4025-b344-110963ff51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53aa20-94f7-425d-8ab7-9ef0a4169464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f28868-eec7-4993-9653-f88da00f9b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330c70a-5134-481f-86eb-1d4f4b232172",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797b5ed-eabb-4ccd-8d6e-a68b939e5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations = pd.DataFrame(json_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ffa75-e566-4f47-8e2a-625938b336f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28356bf5-eda6-4637-b174-9269f0765490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations[df_evaluations.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cf76d-12cc-4d9d-838d-4cb0540a8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbdb91-da1a-4991-9a25-785066901202",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f50e2-077a-459d-90e3-3d2051e76f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73124f-416e-47fe-8f7e-b4a316ddddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_2 = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt2_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_2.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4968179-6f6e-43ee-b461-29f8d7d1d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations_2 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_2):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations_2.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb781f0-962f-4113-a86c-6324d79a4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2 = pd.DataFrame(json_evaluations_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f7887-7a95-4e5d-b93a-decf505c0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2[df_evaluations_2.Relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f861c0-f117-4447-8410-3976448bd1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cfc2b-338c-4147-8b1a-69990d20e6f4",
   "metadata": {},
   "source": [
    "## Saving all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207212c-3d81-4027-93e7-74da7c7184b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o.to_csv('data/results-gpt4o-cosine.csv', index=False)\n",
    "df_gpt35.to_csv('data/results-gpt35-cosine.csv', index=False)\n",
    "df_gpt4o_mini.to_csv('data/results-gpt4o-mini-cosine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bdfb2a-3d45-4276-9006-dd217dae9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.to_csv('data/evaluations-aqa.csv', index=False)\n",
    "df_evaluations_2.to_csv('data/evaluations-qa.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
